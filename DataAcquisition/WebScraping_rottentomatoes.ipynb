{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining Project: Milestone 1 (Part 1)\n",
    "### Web Scraping (Part 1): Scrap movie info and user reviews from rottentomatoes.com \n",
    "1. Obtain a list of urls of the latest 250 movies with DVD or Streaming options available  \n",
    "2. For each movie, scrap the information and ratings. (Structured Data)\n",
    "3. For each movie, scrap the user reviews. (Unstructured Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install selenium bs4 joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time                  \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver                    \n",
    "from selenium.webdriver.common.keys import Keys                      \n",
    "import re\n",
    "import pandas as pd\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_latest_list_of_movies(URL = 'https://www.rottentomatoes.com/browse/dvd-streaming-all', maxcount = 250):\n",
    "    # Launch Firefox using selenium package\n",
    "    browser = webdriver.Firefox(executable_path=\"./geckodriver-v0.25.0-win64/geckodriver.exe\")  \n",
    "    \n",
    "    # Browse to the page listing all movies with DVD or Streaming options available  \n",
    "    browser.get(URL) \n",
    "    time.sleep(2) # Wait for \"Show More\" button to appear \n",
    "    \n",
    "    # Click the \"Show More\" button to get all the required movies listed in the page.\n",
    "    total_click_counts = int(maxcount/32)+2\n",
    "    for j in range(total_click_counts):\n",
    "        browser.find_element_by_class_name('mb-load-btn').click() # Click \"Show More\"\n",
    "        time.sleep(1.5) # Wait for button to appear \n",
    "    html_source = browser.page_source\n",
    "    soup = BeautifulSoup(html_source, 'html.parser')\n",
    "    \n",
    "    # Close the browser\n",
    "    browser.close() \n",
    "    \n",
    "    # Obtain the url to the page containing the movie information for each movie\n",
    "    partial_movies_urls = [link.find(\"a\").get(\"href\") for link in soup.find_all(\"div\", class_=\"movie_info\")]\n",
    "    each_movies_urls = [\"https://www.rottentomatoes.com\" + j for j in partial_movies_urls]\n",
    "    \n",
    "    return each_movies_urls[:maxcount]\n",
    "\n",
    "def get_movie_info_and_rating(url_movie):\n",
    "    # For each movie, we will scrap all the relevant information and ratings of the movie\n",
    "    content = requests.get(url_movie)\n",
    "    soup = BeautifulSoup(content.text, 'html.parser')\n",
    "\n",
    "    movie_info = {}\n",
    "\n",
    "    try:\n",
    "        # Title\n",
    "        title = soup.find(\"h1\", class_=\"mop-ratings-wrap__title mop-ratings-wrap__title--top\").text\n",
    "        \n",
    "        # Critics Consensus\n",
    "        critics_consensus = soup.find(\"p\", class_=\"mop-ratings-wrap__text mop-ratings-wrap__text--concensus\")\n",
    "        critics_consensus = critics_consensus.text if critics_consensus is not None else \"\"\n",
    "    except:\n",
    "        return {}\n",
    "        \n",
    "    # Rotten Tomatoes rating\n",
    "    try:\n",
    "        tomatometer = [item.text.strip() for item in soup.find_all(\"span\", class_=\"mop-ratings-wrap__percentage\")][0]\n",
    "    except:\n",
    "        tomatometer = None\n",
    "        \n",
    "    # Audience rating\n",
    "    try:\n",
    "        audience_score = [item.text.strip() for item in soup.find_all(\"span\", class_=\"mop-ratings-wrap__percentage\")][1]\n",
    "    except:\n",
    "        audience_score = None\n",
    "    \n",
    "    # Number of Rotten Tomatoes rating given to the movie\n",
    "    try: \n",
    "        tomatometer_count = soup.find(\"small\", class_=\"mop-ratings-wrap__text--small\").text.strip()\n",
    "    except:\n",
    "        tomatometer_count = None\n",
    "    \n",
    "     # Number of user rating given to the movie\n",
    "    try:    \n",
    "        user_rating_count = soup.find_all(\"strong\", class_=\"mop-ratings-wrap__text--small\")[1].text.strip().split(\":\")[1]\n",
    "    except:\n",
    "        user_rating_count = None\n",
    "    \n",
    "    # Return a dictionary containing all these data\n",
    "    for item in soup.find_all(\"li\", class_ = \"meta-row clearfix\"):\n",
    "        key = item.find(\"div\", class_ = \"meta-label subtle\").text.strip()\n",
    "        val = item.find(\"div\", class_ = \"meta-value\").text.strip()\n",
    "        movie_info[key] = val\n",
    "    \n",
    "    movie_info[\"title\"] = title\n",
    "    movie_info[\"critics_consensus\"] = critics_consensus\n",
    "    movie_info[\"tomatometer\"] = tomatometer\n",
    "    movie_info[\"audience_score\"] = audience_score\n",
    "    movie_info[\"tomatometer_count\"] = tomatometer_count\n",
    "    movie_info[\"user_rating_count\"] = user_rating_count\n",
    "    movie_info[\"url\"] = url_movie\n",
    "\n",
    "    return movie_info\n",
    "\n",
    "def get_reviews_list(url_movie):\n",
    "    page_number = 1\n",
    "    reviews_list = []\n",
    "    while True:\n",
    "        # For each page of reviews, scrap all the reviews and append them to the reviews_list.\n",
    "        url_review = url_movie + \"/reviews?page=\" + str(page_number)\n",
    "        content = requests.get(url_review)\n",
    "        soup = BeautifulSoup(content.text, 'html.parser')\n",
    "        item_list = soup.find_all(\"div\", class_=\"row review_table_row\")\n",
    "        if len(item_list) == 0:\n",
    "            return reviews_list\n",
    "        \n",
    "        for item in item_list:\n",
    "            review_item = item.find(\"div\", class_ = \"the_review\")\n",
    "            if review_item is None:\n",
    "                return reviews_list\n",
    "            one_review = review_item.text.strip()\n",
    "            reviews_list.append(one_review)\n",
    "\n",
    "        page_number = page_number + 1\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Obtain the list of urls to the latest 250 movies with DVD or Streaming options available  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "movies_urls = find_latest_list_of_movies(maxcount = 5000)\n",
    "movies_urls[0:10] # preview a few urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. For each movie, scrap the information and ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "movie_info = []\n",
    "for url_movie in movies_urls:\n",
    "    movie_info.append(get_movie_info_and_rating(url_movie))\n",
    "    print(\"Completed:\", url_movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_info_clean = [j for j in movie_info if j is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(movie_info)\n",
    "df = pd.DataFrame(movie_info_clean)\n",
    "# df.head() # Preview of the data\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Temporarily store these data in CSV. \n",
    "*These data will be stored in the Hive Data Warehouse in the next milestone.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"movie_info_2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. For each movie, scrap the user reviews.\n",
    "*This will take approximately 20 minutes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# We will assign the list of user reviews to a dictionary with the url as the key\n",
    "movie_reviews = {}\n",
    "for url_movie in movies_urls:\n",
    "    reviews = get_reviews_list(url_movie)\n",
    "    movie_reviews[url_movie] = reviews     \n",
    "    print(\"Completed:\", url_movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A slow but deep film, with extraordinary performances. [Full review in Spanish]',\n",
       " 'As long as it takes',\n",
       " 'An example of a beautifully crafted and photographed, low-key thriller that doubles as a terrific character study about marginalized people.',\n",
       " 'Lacks necessary tension and stakes when the circumstances tell us there should definitely be some.',\n",
       " 'Paul and young Danny Murphy are terrific together, with Paul playing a wounded bear growling his lines and Murphy delivering a fully realized performance.',\n",
       " \"It won't lay a finger on you or look you in the eyes for longer than you're comfortable with. All told, its existence is difficult to justify, but it's here, and it's not bad.\",\n",
       " '... captures its harsh wintry setting, while sharp performances elevate the otherwise mediocre material, which struggles to build consistent suspense to match its intriguing concept.',\n",
       " \"It's a premise in search of a plot.\",\n",
       " 'Every frame is filled with significant, illuminating details.',\n",
       " \"They easily could have turned this setup into a thriller, but instead, they've made a quiet, thoughtful film...\"]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews[movies_urls[10]][0:10] # Preview some user reviews of a movie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Temporarily save the dictionary as python pickled data (*.pkl format)\n",
    "*These data will be stored in the Hive Data Warehouse in the next milestone.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['movie_reviews_5000.pkl']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Temporarily save the dictionary as python pickled data *.pkl\n",
    "joblib.dump(movie_reviews, filename = \"movie_reviews_5000.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4886"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movie_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
