{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web Scraping on Movie Info and Reviews from rottentomatoes.com \n",
    "1. Obtain a list of urls of the latest 250 movies with DVD or Streaming options available  \n",
    "2. For each movie, scrap the information and ratings. (Structured Data)\n",
    "3. For each movie, scrap the user reviews. (Unstructured Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time                  \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver                    \n",
    "from selenium.webdriver.common.keys import Keys                      \n",
    "import re\n",
    "import pandas as pd\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_latest_list_of_movies(URL = 'https://www.rottentomatoes.com/browse/dvd-streaming-all', maxcount = 250):\n",
    "    # Launch Firefox using selenium package\n",
    "    browser = webdriver.Firefox(executable_path=\"./geckodriver-v0.25.0-win64/geckodriver.exe\")  \n",
    "    \n",
    "    # Browse to the page listing all movies with DVD or Streaming options available  \n",
    "    browser.get(URL) \n",
    "    time.sleep(2) # Wait for \"Show More\" button to appear \n",
    "    \n",
    "    # Click the \"Show More\" button to get all the required movies listed in the page.\n",
    "    total_click_counts = int(maxcount/32)+2\n",
    "    for j in range(total_click_counts):\n",
    "        browser.find_element_by_class_name('mb-load-btn').click() # Click \"Show More\"\n",
    "        time.sleep(1.5) # Wait for button to appear \n",
    "    html_source = browser.page_source\n",
    "    soup = BeautifulSoup(html_source, 'html.parser')\n",
    "    \n",
    "    # Close the browser\n",
    "    browser.close() \n",
    "    \n",
    "    # Obtain the url to the page containing the movie information for each movie\n",
    "    partial_movies_urls = [link.find(\"a\").get(\"href\") for link in soup.find_all(\"div\", class_=\"movie_info\")]\n",
    "    each_movies_urls = [\"https://www.rottentomatoes.com\" + j for j in partial_movies_urls]\n",
    "    \n",
    "    return each_movies_urls[:maxcount]\n",
    "\n",
    "def get_movie_info_and_rating(url_movie):\n",
    "    # For each movie, we will scrap all the relevant information and ratings of the movie\n",
    "    content = requests.get(url_movie)\n",
    "    soup = BeautifulSoup(content.text, 'html.parser')\n",
    "\n",
    "    movie_info = {}\n",
    "    \n",
    "    # Title\n",
    "    title = soup.find(\"h1\", class_=\"mop-ratings-wrap__title mop-ratings-wrap__title--top\").text\n",
    "    \n",
    "    # Critics Consensus\n",
    "    critics_consensus = soup.find(\"p\", class_=\"mop-ratings-wrap__text mop-ratings-wrap__text--concensus\")\n",
    "    critics_consensus = critics_consensus.text if critics_consensus is not None else \"\"\n",
    "        \n",
    "    # Rotten Tomatoes rating\n",
    "    try:\n",
    "        tomatometer = [item.text.strip() for item in soup.find_all(\"span\", class_=\"mop-ratings-wrap__percentage\")][0]\n",
    "    except:\n",
    "        tomatometer = None\n",
    "        \n",
    "    # Audience rating\n",
    "    try:\n",
    "        audience_score = [item.text.strip() for item in soup.find_all(\"span\", class_=\"mop-ratings-wrap__percentage\")][1]\n",
    "    except:\n",
    "        audience_score = None\n",
    "    \n",
    "    # Number of Rotten Tomatoes rating given to the movie\n",
    "    try: \n",
    "        tomatometer_count = soup.find(\"small\", class_=\"mop-ratings-wrap__text--small\").text.strip()\n",
    "    except:\n",
    "        tomatometer_count = None\n",
    "    \n",
    "     # Number of user rating given to the movie\n",
    "    try:    \n",
    "        user_rating_count = soup.find_all(\"strong\", class_=\"mop-ratings-wrap__text--small\")[1].text.strip().split(\":\")[1]\n",
    "    except:\n",
    "        user_rating_count = None\n",
    "    \n",
    "    # Return a dictionary containing all these data\n",
    "    for item in soup.find_all(\"li\", class_ = \"meta-row clearfix\"):\n",
    "        key = item.find(\"div\", class_ = \"meta-label subtle\").text.strip()\n",
    "        val = item.find(\"div\", class_ = \"meta-value\").text.strip()\n",
    "        movie_info[key] = val\n",
    "    \n",
    "    movie_info[\"title\"] = title\n",
    "    movie_info[\"critics_consensus\"] = critics_consensus\n",
    "    movie_info[\"tomatometer\"] = tomatometer\n",
    "    movie_info[\"audience_score\"] = audience_score\n",
    "    movie_info[\"tomatometer_count\"] = tomatometer_count\n",
    "    movie_info[\"user_rating_count\"] = user_rating_count\n",
    "    movie_info[\"url\"] = url_movie\n",
    "\n",
    "    return movie_info\n",
    "\n",
    "def get_reviews_list(url_movie):\n",
    "    page_number = 1\n",
    "    while True:\n",
    "        # For each page of reviews, scrap all the reviews and append them to the reviews_list.\n",
    "        url_review = url_movie + \"/reviews?page=\" + str(page_number)\n",
    "        content = requests.get(url_review)\n",
    "        soup = BeautifulSoup(content.text, 'html.parser')\n",
    "        reviews_list = []\n",
    "        for item in soup.find_all(\"div\", class_=\"row review_table_row\"):\n",
    "            review_item = item.find(\"div\", class_ = \"the_review\")\n",
    "            if review_item is None:\n",
    "                return reviews_list\n",
    "            one_review = review_item.text.strip()\n",
    "            reviews_list.append(one_review)\n",
    "\n",
    "        page_number = page_number + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the list of urls to the latest 250 movies with DVD or Streaming options available  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_urls = find_latest_list_of_movies(maxcount = 250)\n",
    "movies_urls[0:10] # preview a few urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For each movie, scrap the information and ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "movie_info = []\n",
    "for url_movie in movies_urls:\n",
    "    movie_info.append(get_movie_info_and_rating(url_movie))\n",
    "    print(\"Completed:\", url_movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(movie_info)\n",
    "df.head() # Preview of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporarily store these data in CSV\n",
    "df.to_csv(\"movie_info.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For each movie, scrap the user reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# We will assign the list of user reviews to a dictionary with the url as the key\n",
    "movie_reviews = {}\n",
    "for url_movie in movies_urls:\n",
    "    reviews = get_reviews_list(url_movie)\n",
    "    movie_reviews[url_movie] = reviews     \n",
    "    print(\"Completed:\", url_movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_reviews[movies_urls[10]][0:10] # Preview some user reviews of a movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporarily save the dictionary as python pickled data *.pkl\n",
    "joblib.dump(movie_reviews, filename = \"movie_reviews.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
