{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis on Rotten Tomatoes Review Data\n",
    "\n",
    "We will attempt to convert our unstructured data, namely reviews data collected from RottenTomatoes to sentiment score. To do this, we will train the model using the Large Movie Review Dataset v1.0 <http://ai.stanford.edu/~amaas/data/sentiment/> [3].\n",
    "  \n",
    "Full credit given to Aaron Kub for writing the article on applying sentiment analysis on the Large Movie Review Dataset v1.0 [1,2]. His code will be adapted to train a model to classify sentiment of a review, and the model will be used to classify our collection of RottenTomatoes reviews data and output an aggregate review's sentiment score for each movie.\n",
    "\n",
    "\n",
    "**References**  \n",
    "[1] https://towardsdatascience.com/sentiment-analysis-with-python-part-1-5ce197074184  \n",
    "[2] https://towardsdatascience.com/sentiment-analysis-with-python-part-2-4f71e7bde59a  \n",
    "[3] Andrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng, and Christopher Potts. (2011). Learning Word Vectors for Sentiment Analysis. The 49th Annual Meeting of the Association for Computational Linguistics (ACL 2011)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and Extract the Data\n",
    "Download the data from <http://ai.stanford.edu/~amaas/data/sentiment/> and extract aclImdb_v1.tar twice and place the aclImdb in the same directory as this notebook.\n",
    "\n",
    "### Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_pos = glob.glob('./aclImdb/train/pos/*.txt')\n",
    "# train_neg = glob.glob('./aclImdb/train/neg/*.txt')\n",
    "# train_files = train_pos + train_neg\n",
    "\n",
    "# test_pos = glob.glob('./aclImdb/test/pos/*.txt')\n",
    "# test_neg = glob.glob('./aclImdb/test/neg/*.txt')\n",
    "# test_files = test_pos + test_neg\n",
    "\n",
    "# reviews_train = []\n",
    "# for f in train_files:\n",
    "#     try:\n",
    "#         with open(f, encoding=\"utf8\") as f2:\n",
    "#             first_line = f2.readline().strip()\n",
    "#             reviews_train.append(first_line.strip())\n",
    "#     except:\n",
    "#         print(f)\n",
    "        \n",
    "# reviews_test = []\n",
    "# for f in test_files:\n",
    "#     try:\n",
    "#         with open(f, encoding=\"utf8\") as f2:\n",
    "#             first_line = f2.readline().strip()\n",
    "#             reviews_test.append(first_line.strip())\n",
    "#     except:\n",
    "#         print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the data in pkl format to reduce read time next time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib\n",
    "# joblib.dump(reviews_train, \"train.pkl\")\n",
    "# joblib.dump(reviews_test, \"test.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data (previously saved as pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_train = joblib.load(\"train.pkl\")\n",
    "reviews_test = joblib.load(\"test.pkl\")\n",
    "    \n",
    "target = [1 if i < 12500 else 0 for i in range(25000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the review data\n",
    "- Remove special characters or extra spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "REPLACE_NO_SPACE = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\?)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])|(\\d+)\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "NO_SPACE = \"\"\n",
    "SPACE = \" \"\n",
    "\n",
    "def preprocess_reviews(reviews):\n",
    "    \n",
    "    reviews = [REPLACE_NO_SPACE.sub(NO_SPACE, line.lower()) for line in reviews]\n",
    "    reviews = [REPLACE_WITH_SPACE.sub(SPACE, line) for line in reviews]\n",
    "    \n",
    "    return reviews\n",
    "\n",
    "reviews_train_clean = preprocess_reviews(reviews_train)\n",
    "reviews_test_clean = preprocess_reviews(reviews_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Model\n",
    "- We will use the final model proposed by Aaron Kub in his article (part 2).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "stop_words = ['in', 'of', 'at', 'a', 'the']\n",
    "ngram_vectorizer = CountVectorizer(binary=True, ngram_range=(1, 3), stop_words=stop_words)\n",
    "ngram_vectorizer.fit(reviews_train_clean)\n",
    "X = ngram_vectorizer.transform(reviews_train_clean)\n",
    "X_test = ngram_vectorizer.transform(reviews_test_clean)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, target, train_size = 0.75\n",
    ")\n",
    "final = LinearSVC(C=0.01)\n",
    "final.fit(X, target)\n",
    "print(\"Final Accuracy: %s\" % accuracy_score(target, final.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model in pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sentiment_model.pkl']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(final, \"sentiment_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top positive features and negative features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('excellent', 0.27778915159678536)\n",
      "('perfect', 0.21944130971718084)\n",
      "('wonderful', 0.20303176870579795)\n",
      "('great', 0.19436777630747099)\n",
      "('amazing', 0.1925965525252106)\n",
      "('superb', 0.17824207494793734)\n",
      "('enjoyed', 0.17514059273124252)\n",
      "('must see', 0.17499908843269293)\n",
      "('enjoyable', 0.1688088747135193)\n",
      "('favorite', 0.1683839906705165)\n",
      "\n",
      "\n",
      "\n",
      "('worst', -0.3990599590725215)\n",
      "('awful', -0.30139933561879434)\n",
      "('waste', -0.2964901976169115)\n",
      "('boring', -0.27275377562767644)\n",
      "('bad', -0.24096709832080834)\n",
      "('terrible', -0.2393709257471478)\n",
      "('disappointment', -0.23196698267614316)\n",
      "('poorly', -0.22648068843833707)\n",
      "('poor', -0.22509660757588298)\n",
      "('dull', -0.21996306004150176)\n"
     ]
    }
   ],
   "source": [
    "feature_to_coef = {\n",
    "    word: coef for word, coef in zip(\n",
    "        ngram_vectorizer.get_feature_names(), final.coef_[0]\n",
    "    )\n",
    "}\n",
    "\n",
    "for best_positive in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1], \n",
    "    reverse=True)[:10]:\n",
    "    print (best_positive)\n",
    "    \n",
    "print(\"\\n\\n\")\n",
    "for best_negative in sorted(\n",
    "    feature_to_coef.items(), \n",
    "    key=lambda x: x[1])[:10]:\n",
    "    print (best_negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Rotten Tomatoes Review Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df = pd.read_csv(\"hive_movie_reviews_semisep.csv\", sep = \";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_list = preprocess_reviews(review_df[\"review\"].astype(str))\n",
    "X_reviews = ngram_vectorizer.transform(reviews_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the sentiment score for each review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_score = final.predict(X_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df[\"sentiment_score\"] = sentiment_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of predicted sentiment score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gun Shy is unlikely to leave much of an impression, even on those who've followed Banderas's interestingly hit-and-miss career.\n",
      "It's loud and dumb and irritating and forgettable.\n",
      "This lackluster comic thriller never matches the over-the-top enthusiasm of its star.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>url_id</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>131995</th>\n",
       "      <td>Gun Shy is unlikely to leave much of an impres...</td>\n",
       "      <td>https://www.rottentomatoes.com/m/gun_shy_2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131996</th>\n",
       "      <td>It's loud and dumb and irritating and forgetta...</td>\n",
       "      <td>https://www.rottentomatoes.com/m/gun_shy_2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131997</th>\n",
       "      <td>This lackluster comic thriller never matches t...</td>\n",
       "      <td>https://www.rottentomatoes.com/m/gun_shy_2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131998</th>\n",
       "      <td>Gun Shy somehow manages to come across as bein...</td>\n",
       "      <td>https://www.rottentomatoes.com/m/gun_shy_2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131999</th>\n",
       "      <td>Random moments are not nearly enough to recomm...</td>\n",
       "      <td>https://www.rottentomatoes.com/m/gun_shy_2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132000</th>\n",
       "      <td>There's desperation for laughs, and then there...</td>\n",
       "      <td>https://www.rottentomatoes.com/m/gun_shy_2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132001</th>\n",
       "      <td>... witless dialogue and a plot that has no id...</td>\n",
       "      <td>https://www.rottentomatoes.com/m/gun_shy_2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132002</th>\n",
       "      <td>The biggest problem for \"Gun Shy\" isn't its ri...</td>\n",
       "      <td>https://www.rottentomatoes.com/m/gun_shy_2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132003</th>\n",
       "      <td>Antonio Banderas hams it up in this dumber tha...</td>\n",
       "      <td>https://www.rottentomatoes.com/m/gun_shy_2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   review  \\\n",
       "131995  Gun Shy is unlikely to leave much of an impres...   \n",
       "131996  It's loud and dumb and irritating and forgetta...   \n",
       "131997  This lackluster comic thriller never matches t...   \n",
       "131998  Gun Shy somehow manages to come across as bein...   \n",
       "131999  Random moments are not nearly enough to recomm...   \n",
       "132000  There's desperation for laughs, and then there...   \n",
       "132001  ... witless dialogue and a plot that has no id...   \n",
       "132002  The biggest problem for \"Gun Shy\" isn't its ri...   \n",
       "132003  Antonio Banderas hams it up in this dumber tha...   \n",
       "\n",
       "                                               url_id  sentiment_score  \n",
       "131995  https://www.rottentomatoes.com/m/gun_shy_2017                0  \n",
       "131996  https://www.rottentomatoes.com/m/gun_shy_2017                0  \n",
       "131997  https://www.rottentomatoes.com/m/gun_shy_2017                1  \n",
       "131998  https://www.rottentomatoes.com/m/gun_shy_2017                0  \n",
       "131999  https://www.rottentomatoes.com/m/gun_shy_2017                0  \n",
       "132000  https://www.rottentomatoes.com/m/gun_shy_2017                0  \n",
       "132001  https://www.rottentomatoes.com/m/gun_shy_2017                0  \n",
       "132002  https://www.rottentomatoes.com/m/gun_shy_2017                0  \n",
       "132003  https://www.rottentomatoes.com/m/gun_shy_2017                0  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(review_df.loc[review_df.url_id == \"https://www.rottentomatoes.com/m/gun_shy_2017\"].iloc[0][\"review\"])\n",
    "print(review_df.loc[review_df.url_id == \"https://www.rottentomatoes.com/m/gun_shy_2017\"].iloc[1][\"review\"])\n",
    "print(review_df.loc[review_df.url_id == \"https://www.rottentomatoes.com/m/gun_shy_2017\"].iloc[2][\"review\"])\n",
    "\n",
    "review_df.loc[review_df.url_id == \"https://www.rottentomatoes.com/m/gun_shy_2017\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate the sentiment score for each movie (url_id) by:\n",
    "- ss_mean: mean of sentiment score (ss)\n",
    "- ss_median: median of ss\n",
    "- ss_p25: 25th percentile of ss\n",
    "- ss_p75: 75th percentile of ss\n",
    "- ss_std: standard deviation of ss\n",
    "- ss_count: Total number of reviews for that movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ss_mean</th>\n",
       "      <th>ss_median</th>\n",
       "      <th>ss_p25</th>\n",
       "      <th>ss_p75</th>\n",
       "      <th>ss_std</th>\n",
       "      <th>ss_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>url_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>https://www.rottentomatoes.com/m/10002519-breaking_point</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://www.rottentomatoes.com/m/1000_times_good_night</th>\n",
       "      <td>0.818182</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.389249</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://www.rottentomatoes.com/m/10011489-bananas</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.516398</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://www.rottentomatoes.com/m/1001_grams</th>\n",
       "      <td>0.909091</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.294245</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://www.rottentomatoes.com/m/1003757-cat_people</th>\n",
       "      <td>0.913043</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.284885</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     ss_mean  ss_median  \\\n",
       "url_id                                                                    \n",
       "https://www.rottentomatoes.com/m/10002519-break...  1.000000        1.0   \n",
       "https://www.rottentomatoes.com/m/1000_times_goo...  0.818182        1.0   \n",
       "https://www.rottentomatoes.com/m/10011489-bananas   0.666667        1.0   \n",
       "https://www.rottentomatoes.com/m/1001_grams         0.909091        1.0   \n",
       "https://www.rottentomatoes.com/m/1003757-cat_pe...  0.913043        1.0   \n",
       "\n",
       "                                                    ss_p25  ss_p75    ss_std  \\\n",
       "url_id                                                                         \n",
       "https://www.rottentomatoes.com/m/10002519-break...    1.00     1.0  0.000000   \n",
       "https://www.rottentomatoes.com/m/1000_times_goo...    1.00     1.0  0.389249   \n",
       "https://www.rottentomatoes.com/m/10011489-bananas     0.25     1.0  0.516398   \n",
       "https://www.rottentomatoes.com/m/1001_grams           1.00     1.0  0.294245   \n",
       "https://www.rottentomatoes.com/m/1003757-cat_pe...    1.00     1.0  0.284885   \n",
       "\n",
       "                                                    ss_count  \n",
       "url_id                                                        \n",
       "https://www.rottentomatoes.com/m/10002519-break...         6  \n",
       "https://www.rottentomatoes.com/m/1000_times_goo...        55  \n",
       "https://www.rottentomatoes.com/m/10011489-bananas          6  \n",
       "https://www.rottentomatoes.com/m/1001_grams               22  \n",
       "https://www.rottentomatoes.com/m/1003757-cat_pe...        46  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss_mean = review_df.groupby(\"url_id\")[\"sentiment_score\"].mean()\n",
    "ss_median = review_df.groupby(\"url_id\")[\"sentiment_score\"].median()\n",
    "ss_p25 = review_df.groupby(\"url_id\")[\"sentiment_score\"].apply(lambda x: np.percentile(x, 25))\n",
    "ss_p75 = review_df.groupby(\"url_id\")[\"sentiment_score\"].apply(lambda x: np.percentile(x, 75))\n",
    "ss_std = review_df.groupby(\"url_id\")[\"sentiment_score\"].std()\n",
    "ss_count = review_df.groupby(\"url_id\")[\"sentiment_score\"].count()\n",
    "\n",
    "ss_df = pd.concat([ss_mean, ss_median, ss_p25, ss_p75, ss_std, ss_count], axis = 1)\n",
    "ss_df.columns = [\"ss_mean\", \"ss_median\", \"ss_p25\", \"ss_p75\", \"ss_std\", \"ss_count\"]\n",
    "ss_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_df.to_csv(\"reviews_5000_sentiment_score.csv\")\n",
    "ss_df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
